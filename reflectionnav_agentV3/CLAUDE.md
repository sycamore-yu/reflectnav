

### **This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.**

### Overview

ReflectionNavV3 is a sophisticated autonomous navigation agent system that uses multi-modal RAG (Retrieval Augmented Generation) for UAV navigation in city environments. It combines visual understanding, experience-based learning, and reflection mechanisms to improve navigation performance over time.

### Architecture

#### ReflectionNav Agent: è¯¦ç»†å¼€å‘æ–‡æ¡£ (V2.1 ä¿®è®¢ç‰ˆ)

**1. æ ¸å¿ƒç†å¿µ ğŸ’¡**
æ™ºèƒ½ä½“çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªå…¨å±€çŠ¶æ€ (AgentState)ï¼Œå®ƒä½œä¸ºæ‰€æœ‰æ“ä½œçš„ä¸­å¤®æ•°æ®æ¢çº½ã€‚æ•´ä¸ªä»»åŠ¡æµç¨‹è¢«æ„å»ºä¸ºä¸€ä¸ªæœ‰å‘å›¾ (Graph)ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªå…·ä½“çš„æ“ä½œï¼ˆå¦‚æ„ŸçŸ¥ã€è§„åˆ’ï¼‰ï¼Œè€Œè¾¹åˆ™ç”±è·¯ç”±å™¨ (Router) æ ¹æ®å½“å‰çŠ¶æ€åŠ¨æ€å†³å®šã€‚æ™ºèƒ½ä½“é¦–å…ˆè¿›è¡Œç¯å¢ƒæ„ŸçŸ¥å’Œè§„åˆ’ï¼Œç„¶åè¿›å…¥ä¸€ä¸ªç”±å¯¼èˆª (Navigate)ã€æœç´¢ (Search)ã€å®šä½ (Locate) ä¸‰ä¸ªä¸“å®¶å·¥ä½œæµç»„æˆçš„å­ä»»åŠ¡å¾ªç¯ã€‚ä»»åŠ¡ç»“æŸåï¼Œç³»ç»Ÿä¼šè¿›å…¥åæ€ (Reflection) é˜¶æ®µï¼Œä»æˆåŠŸæˆ–å¤±è´¥çš„ç»éªŒä¸­å­¦ä¹ ï¼Œå¹¶å°†çŸ¥è¯†å­˜å…¥è®°å¿†æ¨¡å—ä»¥ä¾›æœªæ¥ä½¿ç”¨ã€‚

**2. Agent å…¨å±€çŠ¶æ€ (AgentState) ğŸ“š**
`AgentState` æ˜¯ä¸€ä¸ªè´¯ç©¿ä»»åŠ¡å§‹ç»ˆçš„å…¨å±€æ•°æ®å­—å…¸ï¼ŒåŒ…å«äº†æ™ºèƒ½ä½“è¿è¡Œæ‰€éœ€çš„æ‰€æœ‰é™æ€å’ŒåŠ¨æ€ä¿¡æ¯ã€‚

**2.1. é™æ€ç»„ä»¶ (Static Components)**
è¿™äº›ç»„ä»¶åœ¨ä»»åŠ¡å¼€å§‹æ—¶ä¸€æ¬¡æ€§åˆå§‹åŒ–ï¼Œå¹¶åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¿æŒä¸å˜ã€‚

  * **controller**: `LLMController`: æ™ºèƒ½ä½“çš„åº•å±‚æ§åˆ¶å™¨ï¼Œè´Ÿè´£ä¸ç¯å¢ƒäº¤äº’ï¼ˆå¦‚ç§»åŠ¨ã€æ„ŸçŸ¥ï¼‰å’Œæ‰§è¡ŒåŸºäºåœºæ™¯å›¾çš„æŸ¥è¯¢ã€‚
  * **landmark\_nav\_map**: `LandmarkNavMap`: ç®¡ç†åœ°æ ‡ã€è¯­ä¹‰å’Œç¯å¢ƒåœ°å›¾çš„æ¨¡å—ã€‚å®ƒä¼šæ ¹æ®æ„ŸçŸ¥åˆ°çš„æ–°ä¿¡æ¯è¿›è¡Œå®æ—¶æ›´æ–°ã€‚
  * **episode**: `Episode`: åŒ…å«å½“å‰ä»»åŠ¡çš„æ‰€æœ‰é™æ€ä¿¡æ¯ï¼Œå¦‚ç›®æ ‡æè¿°ã€åœ°å›¾åç§°ã€èµ·å§‹ä½ç½®ç­‰ã€‚
  * **args**: `ExperimentArgs`: å®éªŒé…ç½®å‚æ•°ã€‚
  * **task\_instruction**: `str`: æ¥è‡ª `episode` çš„é¡¶å±‚ä»»åŠ¡ç›®æ ‡æè¿°ã€‚
  * **memory\_module**: `MultiModalMemory`: é•¿æœŸè®°å¿†ä¸­å¿ƒã€‚è¿™æ˜¯ä¸€ä¸ªå‘é‡ç´¢å¼•çš„è®°å¿†æ•°æ®åº“ï¼ŒåŒ…å«äº†å¤šä¸ªé›†åˆï¼ˆcollectionsï¼‰ï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢ã€‚
      * **é›†åˆ 1: `strategic_plan_memory`** - å†å²ä»»åŠ¡çš„ä¸»ä»»åŠ¡è§„åˆ’çš„ç»éªŒæ•™è®­ã€‚
          * é€šè¿‡ `task_instruction` æ£€ç´¢ã€‚
          * `task_instruction`: `str` - ä»»åŠ¡çš„åŸå§‹æŒ‡ä»¤ï¼Œä¹Ÿæ˜¯å‘é‡åŒ–çš„æ¥æºã€‚
          * `master_plan`: `str` - å®Œæ•´çš„ã€ä»¥ JSON å­—ç¬¦ä¸²å½¢å¼å­˜å‚¨çš„åŸå§‹è§„åˆ’ã€‚
          * `reflection_note`: `str` - (Reflection)äº§ç”Ÿçš„å¯¹åŸå§‹è§„åˆ’çš„åˆ†æå’Œæ€è€ƒè¿‡ç¨‹ã€‚
          * `plan_refined`: `str` - (Reflection)è€Œäº§ç”Ÿçš„ä¿®æ­£æˆ–ä¼˜åŒ–çš„è§„åˆ’ã€‚JSON å­—ç¬¦ä¸²å½¢å¼çš„å®Œæ•´ä¿®æ­£åè§„åˆ’/å¦‚æœåŸæœ¬è§„åˆ’æˆåŠŸå®Œæˆäº†ä»»åŠ¡ï¼ŒåŒ…å«JSON å­—ç¬¦ä¸²å½¢å¼çš„å®Œæ•´ä¼˜åŒ–åè§„åˆ’ã€‚
          * `status`: `str` - ä»»åŠ¡çš„æœ€ç»ˆçŠ¶æ€ï¼Œå¦‚ 'success' æˆ– 'failure'ã€‚
      * **é›†åˆ 2: `navigate_experience_memory`** - å¯¼èˆªç›¸å…³çš„ç»éªŒæ•™è®­å’Œå¯¹åº”è¯­ä¹‰å›¾ç‰‡ã€‚
          * **æ£€ç´¢æ–¹å¼**: **ä½¿ç”¨å®Œæ•´çš„ `current_state` å­—ç¬¦ä¸²ä½œä¸ºæŸ¥è¯¢å‘é‡è¿›è¡Œæ£€ç´¢**ã€‚
          * `navigation_goal`: `str` - å¯¼èˆªå­ä»»åŠ¡çš„å…·ä½“ç›®æ ‡ã€‚
          * `is_success`: `str` - è¯¥ç»éªŒæ˜¯å¦æ¥è‡ªä¸€ä¸ªæˆåŠŸçš„å†³ç­– (**å€¼ä¸º 'success' æˆ– 'failure'**)ã€‚
          * `reflect_reason`: `str` - **æ ¸å¿ƒç»éªŒæ•™è®­**ã€‚å¯¹äº**å¤±è´¥ç»éªŒ**ï¼Œè¿™æ˜¯å¯¹å¤±è´¥æ ¹æœ¬åŸå› çš„æ·±å…¥åˆ†æï¼›å¯¹äº**æˆåŠŸç»éªŒ**ï¼Œè¿™æ˜¯å¯¹å†³ç­–ä¸ºä½•æœ‰æ•ˆä»¥åŠå¦‚ä½•ä¼˜åŒ–çš„æ€»ç»“ã€‚
          * `refined_action`: `str` - **ä¿®æ­£æˆ–ç¡®è®¤çš„åŠ¨ä½œ**ã€‚å¯¹äº**å¤±è´¥ç»éªŒ**ï¼Œè¿™æ˜¯åæ€åç”Ÿæˆçš„ã€æœ¬åº”æ‰§è¡Œçš„**ä¿®æ­£åŠ¨ä½œ**ï¼›å¯¹äº**æˆåŠŸç»éªŒ**ï¼Œè¿™å°±æ˜¯å½“æ—¶æ‰§è¡Œå¹¶è¢«éªŒè¯ä¸ºæœ‰æ•ˆçš„**åŸå§‹åŠ¨ä½œ**ã€‚ä¸¤è€…éƒ½ä»¥JSONå­—ç¬¦ä¸²å½¢å¼å­˜å‚¨ã€‚
          * `current_state`: `str` - å…³é”®æ—¶åˆ»çš„æ™ºèƒ½ä½“çŠ¶æ€å¿«ç…§ã€‚
          * `semantic_enhanced_image_b64`: `str` - å¯¹åº”çš„è¯­ä¹‰åœ°å›¾çš„ **Base64 ç¼–ç å­—ç¬¦ä¸²**ã€‚
      * **é›†åˆ 3: `search_and_locate_memory`** - æœç´¢ç›¸å…³çš„ç»éªŒæ•™è®­å’Œå¯¹åº”è¯­ä¹‰å›¾ç‰‡ã€‚
          * **æ£€ç´¢æ–¹å¼**: **ä½¿ç”¨å®Œæ•´çš„ `current_state` å­—ç¬¦ä¸²ä½œä¸ºæŸ¥è¯¢å‘é‡è¿›è¡Œæ£€ç´¢**ã€‚
          * `search_goal`: `str` - æœç´¢å­ä»»åŠ¡çš„å…·ä½“ç›®æ ‡ã€‚
          * `is_success`: `str` - è¯¥ç»éªŒæ˜¯å¦æ¥è‡ªä¸€ä¸ªæˆåŠŸçš„å†³ç­– (**å€¼ä¸º 'success' æˆ– 'failure'**)ã€‚
          * `reflect_reason`: `str` - **æ ¸å¿ƒç»éªŒæ•™è®­**ã€‚å¯¹äº**å¤±è´¥ç»éªŒ**ï¼Œè¿™æ˜¯å¯¹å¤±è´¥æ ¹æœ¬åŸå› çš„æ·±å…¥åˆ†æï¼›å¯¹äº**æˆåŠŸç»éªŒ**ï¼Œè¿™æ˜¯å¯¹å†³ç­–ä¸ºä½•æœ‰æ•ˆä»¥åŠå¦‚ä½•ä¼˜åŒ–çš„æ€»ç»“ã€‚
          * `refined_action`: `str` - **ä¿®æ­£æˆ–ç¡®è®¤çš„åŠ¨ä½œ**ã€‚å¯¹äº**å¤±è´¥ç»éªŒ**ï¼Œè¿™æ˜¯åæ€åç”Ÿæˆçš„ã€æœ¬åº”æ‰§è¡Œçš„**ä¿®æ­£åŠ¨ä½œ**ï¼›å¯¹äº**æˆåŠŸç»éªŒ**ï¼Œè¿™å°±æ˜¯å½“æ—¶æ‰§è¡Œå¹¶è¢«éªŒè¯ä¸ºæœ‰æ•ˆçš„**åŸå§‹åŠ¨ä½œ**ã€‚ä¸¤è€…éƒ½ä»¥JSONå­—ç¬¦ä¸²å½¢å¼å­˜å‚¨ã€‚
          * `current_state`: `str` - å…³é”®æ—¶åˆ»çš„æ™ºèƒ½ä½“çŠ¶æ€å¿«ç…§ã€‚
          * `semantic_enhanced_image_b64`: `str` - å¯¹åº”çš„è¯­ä¹‰åœ°å›¾çš„ **Base64 ç¼–ç å­—ç¬¦ä¸²**ã€‚

**2.2. åŠ¨æ€çŠ¶æ€ (Dynamic State)**
è¿™äº›çŠ¶æ€åœ¨ä»»åŠ¡æ‰§è¡ŒæœŸé—´ä¼šä¸æ–­è¢«æ›´æ–°ã€‚

  * `plan`: `Optional[dict]`: ç”± `generate_plan_with_rag` èŠ‚ç‚¹ç”Ÿæˆçš„é«˜çº§åˆ†æ­¥è®¡åˆ’ï¼ŒåŒ…å« `sub_goals` åˆ—è¡¨å’Œ `reason`æ¨ç†è¿‡ç¨‹ã€‚
  * `current_task_index`: `int`: æŒ‡å‘å½“å‰æ­£åœ¨æ‰§è¡Œçš„å­ä»»åŠ¡åœ¨ `plan` ä¸­çš„ç´¢å¼•ã€‚
  * `timestep`: `int`: æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„å½“å‰æ—¶é—´æ­¥ã€‚
  * `current_observation`: `dict`: å½“å‰æ—¶é—´æ­¥çš„ç›´æ¥æ„ŸçŸ¥ç»“æœã€‚è¿™æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ï¼š
      * `'image'`: `np.ndarray` - åŸå§‹çš„ RGB å›¾åƒã€‚
      * `'image_b64'`: `str` - Base64 ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²ã€‚
      * `'scene_description'`: `str` - ç”± VLM ç”Ÿæˆçš„åœºæ™¯æ–‡å­—æè¿°ã€‚
      * `'geoinstruct'`: `str` - ç»“åˆäº†åœ°æ ‡ã€å‘¨å›´ç‰©ä½“çš„åœ°ç†ç©ºé—´ä¸Šä¸‹æ–‡æè¿°ã€‚
  * `subtask_context`: `dict`: ä¸“å®¶äº¤æ¥å¤‡å¿˜å½•ã€‚ç”¨äºåœ¨å­ä»»åŠ¡æ­¥éª¤ä¹‹é—´ä¼ é€’ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«ä¸Šä¸€æ­¥çš„ `{ goal, CoT_summary, movement }`ã€‚
  * `current_state`: `str`: ä¸º RAG å’Œåæ€è®¾è®¡çš„çŠ¶æ€å¿«ç…§ã€‚è¿™æ˜¯ä¸€ä¸ªå¤åˆå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºï¼š`"Current aerial perspective observation: {'scene_description': str+'geoinstruct': str}. Task: {é¡¶å±‚ä»»åŠ¡æŒ‡ä»¤}. Current Goal: {å­ä»»åŠ¡ç›®æ ‡} (Strategy: {å½“å‰ç­–ç•¥})"`ã€‚
  * `trajectory_history`: `List[FrameLog]`: å®Œæ•´çš„è½¨è¿¹å†å²è®°å½•ã€‚ç”¨äºä¸ºæœ€ç»ˆçš„åæ€æ¨¡å—è®°å½•æ¯ä¸ªæ—¶é—´å¸§çš„è¯¦ç»†æ—¥å¿—ã€‚`FrameLog` åŒ…å«ï¼š
      * `current_state`
      * `movement reason` (ä¸“å®¶è¾“å‡ºçš„JSON)
      * `map_snapshot` (è¯¥æ­¥éª¤çš„åœ°å›¾å›¾åƒ)
      * `timestep`, `pose` (x,y,z,yaw), `distance_to_target`

**2.3. æœ€ç»ˆç»“æœ (Final Result)**
åœ¨ä»»åŠ¡ç»“æŸæ—¶è®¾ç½®ï¼Œç”¨äºè®°å½•æœ€ç»ˆçš„æ‰§è¡Œç»“æœã€‚

  * `mission_success`: `bool`: ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆçš„æ ‡å¿—ã€‚
  * `final_reason`: `str`: ä»»åŠ¡ç»“æŸçš„åŸå› ï¼Œä¾‹å¦‚ 'success', 'timeout', 'goal\_unreachable'ã€‚

**3. ä¸»å·¥ä½œæµå›¾ (Main Workflow Graph) ğŸ—ºï¸**
ä¸»å·¥ä½œæµæ˜¯æ™ºèƒ½ä½“çš„é«˜å±‚æ§åˆ¶å¾ªç¯ï¼Œè´Ÿè´£åè°ƒæ„ŸçŸ¥ã€è§„åˆ’å’Œå­ä»»åŠ¡æ‰§è¡Œã€‚

**3.1. æ„ŸçŸ¥å†³ç­– (should\_perceive? Router)**

  * **å†³ç­–é—®é¢˜**: æ˜¯å¦éœ€è¦æ‰§è¡Œæ„ŸçŸ¥æ“ä½œï¼Ÿ
  * **åˆ†æ”¯**:
      * **æ˜¯ (Yes)**: å¦‚æœæ˜¯ä»»åŠ¡çš„ç¬¬ä¸€æ­¥ï¼Œæˆ–è¾¾åˆ°äº†é¢„è®¾çš„æ„ŸçŸ¥æ—¶é—´/è·ç¦»é—´éš”ã€‚æµå‘ `perceive_and_model` èŠ‚ç‚¹ã€‚
      * **å¦ (No)**: å¦‚æœæœªè¾¾åˆ°æ„ŸçŸ¥é—´éš”ã€‚è·³è¿‡æ„ŸçŸ¥ï¼Œç›´æ¥æµå‘è§„åˆ’å†³ç­–ã€‚

**3.2. èŠ‚ç‚¹ A: perceive\_and\_model (æ„ŸçŸ¥ä¸å»ºæ¨¡)**

  * **èŒè´£**: æ„ŸçŸ¥å¤–éƒ¨ä¸–ç•Œï¼Œå¹¶æ›´æ–°æ™ºèƒ½ä½“çš„å†…éƒ¨ä¸–ç•Œæ¨¡å‹å’ŒçŸ­æœŸè®°å¿†ã€‚
  * **è¾“å…¥**: `controller.pose` (å½“å‰ä½å§¿)ã€‚
  * **æ ¸å¿ƒé€»è¾‘ä¸ä¿¡æ¯å­˜å…¥**:
    1.  **è·å–è§‚æµ‹**: è°ƒç”¨ `controller.perceive` è·å¾—åŸå§‹ RGB å›¾åƒã€‚
    2.  **æ›´æ–°åœ°å›¾**: è°ƒç”¨ `landmark_nav_map.update_observations`ï¼Œå°†æ–°çš„ RGB å›¾åƒä¿¡æ¯èåˆè¿›å†…éƒ¨çš„å¯¼èˆªåœ°å›¾ä¸­ã€‚
    3.  **ç”Ÿæˆæè¿°**: è°ƒç”¨ VLM (`llm_manager.generate_image_caption`) ä¸ºå½“å‰ RGB å›¾åƒç”Ÿæˆä¸€æ®µæ–‡å­—æè¿° (`scene_description`)ã€‚
    4.  **æ›´æ–°åœºæ™¯å›¾**: **è°ƒç”¨ `controller.understand` å’Œ `controller.build_scene_graph` æ¥æ„ŸçŸ¥å¹¶æ›´æ–°åœºæ™¯å›¾æ•°æ®åº“ï¼Œç¡®ä¿æŒç»­æ„å»ºå¯¹ç¯å¢ƒçš„å…¨é¢è®¤çŸ¥ã€‚**
    5.  **æ„å»ºåœ°ç†æŒ‡ä»¤**: ç»¼åˆåœ°æ ‡ã€åœºæ™¯å›¾ç‰©ä½“ç­‰ä¿¡æ¯ï¼Œæ„å»º `geoinstruct` å­—ç¬¦ä¸²ã€‚
    6.  **æ›´æ–° AgentState (çŸ­æœŸè®°å¿†)**:
          * å°†ä¸Šè¿°ç»“æœå­˜å…¥ `AgentState.current_observation` å­—å…¸ä¸­ã€‚
  * **æµå‘**: `should_generate_plan?` è·¯ç”±å™¨ã€‚

**3.3. è§„åˆ’å†³ç­– (should\_generate\_plan? Router)**

  * **å†³ç­–é—®é¢˜**: æ˜¯å¦éœ€è¦ç”Ÿæˆæ–°çš„é«˜çº§è®¡åˆ’ï¼Ÿ
  * **åˆ†æ”¯**:
      * **æ˜¯ (Yes)**: å¦‚æœ `AgentState.plan` ä¸º `None`ã€‚æµå‘ `generate_plan_with_rag` èŠ‚ç‚¹ã€‚
      * **å¦ (No)**: å¦‚æœè®¡åˆ’å·²å­˜åœ¨ã€‚æµå‘ `execute_subtask_router` èŠ‚ç‚¹ï¼Œå¼€å§‹æ‰§è¡Œå­ä»»åŠ¡ã€‚

**3.4. èŠ‚ç‚¹ C: generate\_plan\_with\_rag (ç”Ÿæˆè§„åˆ’)**

  * **èŒè´£**: ç»“åˆä»è®°å¿† `mainplan_experience_memory` ä¸­æ£€ç´¢åˆ°çš„ç›¸ä¼¼ç»éªŒï¼Œä¸ºå½“å‰ä»»åŠ¡åˆ›å»ºä¸€ä¸ªé«˜å±‚æ¬¡ã€åˆ†æ­¥éª¤çš„è®¡åˆ’ã€‚
  * **æ ¸å¿ƒé€»è¾‘**:
    1.  **RAG**:
          * ä»¥ `task_instruction` ä¸ºæŸ¥è¯¢ï¼Œä» `mainplan_experience_memory` ä¸­æ£€ç´¢æœ€ç›¸ä¼¼çš„è§„åˆ’ä½œä¸º `refined_plan` å’Œå¯¹åº”çš„æ€è€ƒ `reflect_reason`ã€‚
    2.  **Prompt**: å°† RAG æ£€ç´¢åˆ°çš„ `refined_plan` å’Œ `reflect_reason`ï¼Œè¿åŒå½“å‰è§‚æµ‹ `geoinstruct` å’Œä»»åŠ¡ç›®æ ‡ `task_instruction`ï¼Œä¸€èµ·å¡«å…¥ `planner_prompt` æ¨¡æ¿ã€‚
    3.  **LLM è°ƒç”¨**: è¯·æ±‚å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„è®¡åˆ’ã€‚å…¶è¾“å‡ºè¢« `PlanOutput` æ¨¡å‹è§£æï¼ŒåŒ…å« `sub_goals` åˆ—è¡¨ï¼ˆæ¯ä¸ªsub-goalå«`goal`, `strategy`, `desired_state`ï¼‰å’Œ `reason`ã€‚
  * **è¾“å‡º**: æ›´æ–° `plan`, `current_task_index` (è®¾ä¸º0), `subtask_context`ã€‚
  * **æµå‘**: `execute_subtask_router` èŠ‚ç‚¹ã€‚

**3.5. èŠ‚ç‚¹ D: execute\_subtask\_router (å­ä»»åŠ¡è·¯ç”±)**

  * **èŒè´£**: æ ¹æ® `plan` ä¸­å½“å‰å­ä»»åŠ¡å®šä¹‰çš„ç­–ç•¥ (`strategy`)ï¼Œå°†å·¥ä½œæµåˆ†æ´¾ç»™ç›¸åº”çš„ä¸“å®¶ã€‚åŒæ—¶ï¼Œå®ƒä¼šæ„å»ºç»Ÿä¸€çš„ `current_state` å¿«ç…§ï¼Œä¾›åç»­çš„ RAG å’Œåæ€æ¨¡å—ä½¿ç”¨ã€‚
  * **è¾“å…¥**: `plan`, `current_task_index`, `current_observation`, `task_instruction`ã€‚
  * **è¾“å‡º**: `current_state` (æ ¼å¼: `"Current aerial perspective observation: {è§‚æµ‹æè¿°}. Task: {é¡¶å±‚ä»»åŠ¡æŒ‡ä»¤}. Current Goal: {å­ä»»åŠ¡ç›®æ ‡} (Strategy: {å½“å‰ç­–ç•¥})"`).
  * **åˆ†æ”¯**:
      * å¦‚æœ `strategy` æ˜¯ 'navigate'ï¼Œæµå‘ Navigate (å¯¼èˆª) ä¸“å®¶å·¥ä½œæµã€‚
      * å¦‚æœ `strategy` æ˜¯ 'search'ï¼Œæµå‘ Search (æœç´¢) ä¸“å®¶å·¥ä½œæµã€‚
      * å¦‚æœ `strategy` æ˜¯ 'locate'ï¼Œæµå‘ Locate (å®šä½) ä¸“å®¶å·¥ä½œæµã€‚
  * **æ³¨æ„**ï¼š`Locate` ä¸“å®¶ä¸å†è¢«å¼ºåˆ¶ä¸ºæœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼Œå¯ä»¥æ ¹æ®è®¡åˆ’åœ¨æµç¨‹ä¸­è¢«å¤šæ¬¡è°ƒç”¨ã€‚

**3.6. èŠ‚ç‚¹ finalize\_step (æœ€ç»ˆåŒ–æ­¥éª¤)**

  * **èŒè´£**: åœ¨ Search (æœç´¢) å’Œ Navigate (å¯¼èˆª) ä¸“å®¶å·¥ä½œæµæ‰§è¡ŒåŠ¨ä½œåï¼Œæ­¤èŠ‚ç‚¹è´Ÿè´£æ›´æ–°æ™ºèƒ½ä½“çš„ç‰©ç†çŠ¶æ€ï¼ˆä½å§¿ã€æ—¶é—´æ­¥ï¼‰å¹¶è®°å½•è½¨è¿¹å†å²ã€‚
  * **è¾“å…¥**: `movement` (ä¸“å®¶è¾“å‡º), `reason` (ä¸“å®¶è¾“å‡º)ã€‚
  * **è¾“å‡º**:
      * `controller.pose` (ç§»åŠ¨åˆ°æ–°ä½å§¿)ã€‚
      * `timestep` (åŠ 1)ã€‚
      * `trajectory_history`: æ·»åŠ ä¸€æ¡åŒ…å«å½“å‰æ‰€æœ‰è¯¦ç»†ä¿¡æ¯çš„ `FrameLog` è®°å½•ã€‚
  * **æµå‘**: `should_continue?` è·¯ç”±å™¨ã€‚

**3.7. å¾ªç¯/ç»“æŸå†³ç­– (should\_continue? Router)**

  * **å†³ç­–é—®é¢˜**: å½“å‰ä»»åŠ¡æ˜¯å¦åº”è¯¥ç»§ç»­ï¼Ÿ
  * **åˆ†æ”¯**:
      * **ç»§ç»­å¾ªç¯ (Continue Loop)**: å¦‚æœä»»åŠ¡æœªå®Œæˆï¼ˆä¾‹å¦‚ï¼Œæœªè¶…æ—¶ä¸”æœªåˆ°è¾¾æœ€ç»ˆç›®æ ‡ï¼‰ã€‚æµå›åˆ°ä¸»å¾ªç¯çš„èµ·ç‚¹ `should_perceive?` è·¯ç”±å™¨ã€‚
      * **ç»“æŸä»»åŠ¡ (End Mission)**: å¦‚æœä»»åŠ¡å·²å®Œæˆæˆ–å¤±è´¥ã€‚æµå‘ `check_mission_success` è·¯ç”±å™¨ã€‚

**4. å­ä»»åŠ¡ä¸“å®¶å·¥ä½œæµ (Sub-Task Expert Workflows) ğŸ§­**
æ¯ä¸ªä¸“å®¶å·¥ä½œæµè´Ÿè´£æ‰§è¡Œä¸€ç§ç‰¹å®šç±»å‹çš„å­ä»»åŠ¡ã€‚

**4.1. Navigate (å¯¼èˆª) ä¸“å®¶**

  * **ç›®æ ‡**: å¯¼èˆªè‡³ä¸€ä¸ªæŒ‡å®šçš„åœ°æ ‡ã€‚
  * **RAG**: **ä½¿ç”¨åœ¨å­ä»»åŠ¡è·¯ç”±é˜¶æ®µç”Ÿæˆçš„å®Œæ•´ `current_state` å­—ç¬¦ä¸²ä½œä¸ºæŸ¥è¯¢å‘é‡**ï¼Œä» `navigation_experience_memory` ä¸­æ£€ç´¢ç›¸å…³çš„ `refined_action` `reflect_reason` å’Œ `retrieved_image_b64` (å¯¹åº”è¯­ä¹‰å›¾ç‰‡)ã€‚
  * **æ‰§è¡Œ (execute\_navigate)**:
      * **Prompt**: ç»“åˆ `subtask_context`, `current_state` å’Œ RAG ç»éªŒ (`refined_action`, `reflect_reason`)ã€‚**VLM çš„è¾“å…¥ä¼šæŒ‰é¡ºåºåŒ…å«ä¸¤å¼ å›¾ç‰‡ï¼šç¬¬ä¸€å¼ æ˜¯è¢«æ ‡è®°ä¸ºâ€œå½“å‰å®æ—¶åœ°å›¾â€çš„å®æ—¶åœ°æ ‡åœ°å›¾ (`gen_map(query_type='landmark')`)ï¼Œç¬¬äºŒå¼ æ˜¯è¢«æ ‡è®°ä¸ºâ€œå†å²ç»éªŒå‚è€ƒåœ°å›¾â€çš„ `retrieved_image_b64`ã€‚Promptä¸­ä¼šæ˜ç¡®æŒ‡ç¤ºæ¨¡å‹ä¸¤å¼ å›¾å„è‡ªçš„èº«ä»½ï¼Œå¼•å¯¼å…¶è¿›è¡Œå¯¹æ¯”åˆ†æã€‚**
      * **è¾“å‡º**: LLM çš„è¾“å‡ºè¢« `NavigationDecisionOutput` æ¨¡å‹è§£æä¸ºä¸€ä¸ªåŒ…å« `movement`, `reason`, `next_strategy`, `confidence` çš„ç»“æ„åŒ–å¯¹è±¡ï¼Œå­˜å…¥ `action_result`ã€‚
  * **å®Œæˆæ£€æŸ¥ (is\_landmark\_reached?)**:
      * **æ˜¯**: å¦‚æœä¸åœ°æ ‡çš„ç‰©ç†è·ç¦»å°äºé˜ˆå€¼ï¼Œæˆ– `next_strategy` å†³ç­–ä¸º 'next\_subtask'ã€‚æµå‘ Finalize & Advanceã€‚
      * **å¦**: å¦åˆ™æµå‘ Finalize & Loopã€‚

**4.2. Search (æœç´¢) ä¸“å®¶**

  * **ç›®æ ‡**: åœ¨ä¸€ä¸ªåŒºåŸŸå†…æœç´¢ç‰¹å®šç›®æ ‡æˆ–ä¿¡æ¯ã€‚
  * **RAG**: **ä½¿ç”¨åœ¨å­ä»»åŠ¡è·¯ç”±é˜¶æ®µç”Ÿæˆçš„å®Œæ•´ `current_state` å­—ç¬¦ä¸²ä½œä¸ºæŸ¥è¯¢å‘é‡**ï¼Œä» `search_experience_memory` æ£€ç´¢ç›¸å…³çš„ `refined_action` `reflect_reason` å’Œ `retrieved_image_b64` (å¯¹åº”è¯­ä¹‰å›¾ç‰‡)ã€‚
  * **æ‰§è¡Œ (execute\_search)**:
      * **Prompt**: ç»“åˆ `subtask_context`, `current_state` å’Œ RAG ç»éªŒ (`refined_action`, `reflect_reason`)ã€‚**VLM çš„è¾“å…¥ä¼šæŒ‰é¡ºåºåŒ…å«ä¸¤å¼ å›¾ç‰‡ï¼šç¬¬ä¸€å¼ æ˜¯è¢«æ ‡è®°ä¸ºâ€œå½“å‰å®æ—¶åœ°å›¾â€çš„å®æ—¶è¯­ä¹‰åœ°å›¾ (`gen_map(query_type='semantic')`)ï¼Œç¬¬äºŒå¼ æ˜¯è¢«æ ‡è®°ä¸ºâ€œå†å²ç»éªŒå‚è€ƒåœ°å›¾â€çš„ `retrieved_image_b64`ã€‚Promptä¸­ä¼šæ˜ç¡®æŒ‡ç¤ºæ¨¡å‹ä¸¤å¼ å›¾å„è‡ªçš„èº«ä»½ï¼Œå¼•å¯¼å…¶è¿›è¡Œå¯¹æ¯”åˆ†æã€‚**
      * **è¾“å‡º**: LLM çš„è¾“å‡ºè¢« `SearchOutput` æ¨¡å‹è§£æä¸ºä¸€ä¸ªåŒ…å« `movement`, `reason`, `decision`, `confidence` çš„ç»“æ„åŒ–å¯¹è±¡ï¼Œå­˜å…¥ `action_result`ã€‚
  * **å®Œæˆæ£€æŸ¥ (is\_target\_info\_sufficient?)**:
      * **æ˜¯**: å¦‚æœ `decision` ä¸º 'next\_subtask' æˆ–æœç´¢è¶…æ—¶ã€‚æµå‘ Finalize & Advanceã€‚
      * **å¦**: å¦‚æœ `decision` ä¸º 'continue\_search'ï¼Œæµå‘ Finalize & Loopã€‚

**4.3. Locate (å®šä½) ä¸“å®¶**

  * **ç›®æ ‡**: ç²¾ç¡®å®šä½ä¸€ä¸ªå·²ç»å¤§è‡´å‘ç°çš„ç›®æ ‡ã€‚
  * **æ‰§è¡Œ (execute\_locate)**:
      * **æ ¸å¿ƒåŠ¨ä½œ**: ä¼˜å…ˆä½¿ç”¨ `controller.query_engine.robust_subgraph_query` å¯¹åœºæ™¯å›¾è¿›è¡Œç»“æ„åŒ–æŸ¥è¯¢ã€‚å¦‚æœå¤±è´¥ï¼Œåˆ™å›é€€åˆ° VLMã€‚
      * **Prompt (VLMå›é€€æ—¶)**: ç»“åˆ `subtask_context`, `current_state` å’Œå½“å‰è§‚æµ‹å›¾åƒï¼Œç›´æ¥è¯·æ±‚ VLM ç»™å‡ºç›®æ ‡åæ ‡ã€‚
      * **è¾“å‡º**: è¾“å‡ºè¢« `LocateOutput` æ¨¡å‹è§£æï¼ŒåŒ…å« `status` ('TARGET\_LOCKED' æˆ– 'SEARCHING\_VICINITY'), `selected_pos` ç­‰ã€‚
  * **å®Œæˆæ£€æŸ¥**: å®šä½æ˜¯ä¸€ä¸ªåŸå­æ“ä½œï¼Œæ‰§è¡Œåç›´æ¥æµå‘ Finalize & Advanceã€‚

**5. ä»»åŠ¡ç»“æŸã€åæ€ä¸å­¦ä¹  (End-of-Mission, Reflection & Learning) ğŸ§ **
å½“ä¸»å¾ªç¯ç»“æŸåï¼Œç³»ç»Ÿè¿›å…¥åæ€é˜¶æ®µï¼Œå¯¹æ•´ä¸ªä»»åŠ¡è¿‡ç¨‹è¿›è¡Œå¤ç›˜å’Œå­¦ä¹ ã€‚æ­¤é˜¶æ®µåˆ†ä¸ºä¸¤ä¸ªå±‚é¢ï¼šå¯¹é«˜å±‚ä¸»è§„åˆ’çš„åæ€ï¼Œä»¥åŠå¯¹åº•å±‚å­ä»»åŠ¡æ‰§è¡Œçš„ç»éªŒæ€»ç»“ã€‚

**5.1. æˆåŠŸå­ä»»åŠ¡ç»éªŒæ€»ç»“ (summarize\_success\_experience)**
å½“ `check_mission_success` è·¯ç”±å™¨åˆ¤æ–­ä»»åŠ¡æˆåŠŸæ—¶ï¼Œè§¦å‘æ­¤æµç¨‹ä»¥æ€»ç»“å­ä»»åŠ¡çš„å…³é”®å†³ç­–ã€‚

  * **è¯»å–è½¨è¿¹**: è¯»å– `AgentState.trajectory_history`ã€‚
  * **LLMåˆ†æ**: å°†å®Œæ•´çš„ `trajectory_history` (ä½œä¸ºJSON) å’Œ `master_plan` å‘é€ç»™ LLMï¼Œä½¿ç”¨ `success_analysis` æç¤ºè¯ï¼Œ**è¦æ±‚å…¶è¯†åˆ«å‡ºå¯¼è‡´ä»»åŠ¡æˆåŠŸçš„å†³ç­–è½¬æŠ˜ç‚¹ï¼Œå¹¶è¿”å›è¯¥è½¬æŠ˜ç‚¹å‘ç”Ÿæ—¶çš„ `timestep` ç´¢å¼•ã€‚æ¨¡å‹ä¼šåˆ†ææ¯ä¸€æ­¥çš„å†³ç­–ï¼ˆ`movement reason`ï¼‰åŠå…¶åç»­ç»“æœï¼Œå®šä½åˆ°æœ€å…³é”®çš„å¯¼èˆªå’Œæœç´¢å†³ç­–å¸§**ï¼Œå¹¶å¯¹è¯¥å¸§å½¢æˆï¼š
      * `reflect_reason`: `str` - æ ¸å¿ƒç»éªŒæ•™è®­ï¼Œè¿™æ˜¯å¯¹æˆåŠŸè·¯å¾„çš„ä¼˜åŒ–æ€è€ƒã€‚
      * `refined_action`: `str` - å½“æ—¶æ‰§è¡Œçš„æˆåŠŸçš„åŸå§‹åŠ¨ä½œã€‚
  * **å†™å…¥è®°å¿†**: è°ƒç”¨ `memory_module.add`ï¼Œæ ¹æ®å¤§æ¨¡å‹æå–çš„å…³é”®å¸§çš„`timestep`,å¾—åˆ°å¯¹åº”çš„è¯­ä¹‰å›¾ç‰‡ï¼Œ`current_state`ï¼Œ`navigation_goal`/`search_goal` å’Œåæ€ç¬”è®° (`reflect_reason`) åŠ `refined_action` ä¸€åŒå­˜å…¥ç›¸åº”çš„ç»éªŒæ•°æ®åº“ä¸­ (`navigation_experience_memory` æˆ– `search_experience_memory`)ã€‚

**5.2. å¤±è´¥å­ä»»åŠ¡ç»éªŒåæ€ (reflect\_on\_failure)**
å½“ `check_mission_success` è·¯ç”±å™¨åˆ¤æ–­ä»»åŠ¡å¤±è´¥æ—¶ï¼Œè§¦å‘æ­¤æµç¨‹ä»¥åæ€å­ä»»åŠ¡çš„å¤±è´¥åŸå› ã€‚

  * **å‡†å¤‡è¾“å…¥**: å°† `failure_reason` å’Œå®Œæ•´çš„ `trajectory_history` (ä½œä¸ºJSON) å¡«å…¥ `failure_analysis` æç¤ºè¯æ¨¡æ¿ã€‚
  * **LLMåæ€**: å°†å®Œæ•´çš„ `trajectory_history` (ä½œä¸ºJSON) å’Œ `master_plan` å‘é€ç»™ LLMï¼Œä½¿ç”¨ `failure_analysis` æç¤ºè¯ï¼Œ**è¦æ±‚å…¶è¯†åˆ«å‡ºå¯¼è‡´ä»»åŠ¡å¤±è´¥çš„å†³ç­–è½¬æŠ˜ç‚¹ï¼Œå¹¶è¿”å›è¯¥è½¬æŠ˜ç‚¹å‘ç”Ÿæ—¶çš„ `timestep` ç´¢å¼•ã€‚æ¨¡å‹ä¼šåˆ†ææ¯ä¸€æ­¥çš„å†³ç­–ï¼ˆ`movement reason`ï¼‰åŠå…¶åç»­ç»“æœï¼Œå®šä½åˆ°æœ€å…³é”®çš„å¯¼èˆªå’Œæœç´¢å†³ç­–å¸§**ï¼Œå¹¶å¯¹è¯¥å¸§å½¢æˆï¼š
      * `reflect_reason`: `str` - æ ¸å¿ƒç»éªŒæ•™è®­ï¼Œè¿™æ˜¯å¯¹å¤±è´¥åŸå› çš„æ€è€ƒå’Œåæ€ã€‚
      * `refined_action`: `str` - ä¿®æ­£ååº”è¯¥æ‰§è¡Œçš„åŠ¨ä½œã€‚
  * **å†™å…¥è®°å¿†**: è°ƒç”¨ `memory_module.add`ï¼Œæ ¹æ®å¤§æ¨¡å‹æå–çš„å…³é”®å¸§çš„`timestep`,å¾—åˆ°å¯¹åº”çš„è¯­ä¹‰å›¾ç‰‡ï¼Œ`current_state`ï¼Œ`navigation_goal`/`search_goal` å’Œåæ€ç¬”è®° (`reflect_reason`) åŠ `refined_action` ä¸€åŒå­˜å…¥ç›¸åº”çš„ç»éªŒæ•°æ®åº“ä¸­ (`navigation_experience_memory` æˆ– `search_experience_memory`)ã€‚

**5.3. ä¸»è§„åˆ’åæ€ä¸ä¼˜åŒ– (reflect\_on\_main\_plan)**
æ­¤æµç¨‹åœ¨ä»»åŠ¡ç»“æŸåè§¦å‘ï¼Œç‹¬ç«‹äºå­ä»»åŠ¡ç»éªŒæ€»ç»“ï¼Œä¸“æ³¨äºä¼˜åŒ–é«˜å±‚çš„ä¸»è§„åˆ’ï¼Œä¸º `mainplan_experience_memory` æä¾›å­¦ä¹ å†…å®¹ã€‚

  * **LLMåˆ†æä¸é‡å†™**: å°†åŸå§‹ä¸»è§„åˆ’ `master_plan`ã€å®Œæ•´çš„ `trajectory_history` ä»¥åŠä»»åŠ¡æœ€ç»ˆçŠ¶æ€ `final_reason` æä¾›ç»™ä¸€ä¸ªå¼ºå¤§çš„LLMã€‚ä½¿ç”¨ä¸“ç”¨çš„ `main_plan_reflection_prompt` æç¤ºè¯ï¼Œè¦æ±‚æ¨¡å‹ï¼š
      * **åˆ†æ**ï¼šæ·±å…¥åˆ†æåŸå§‹è§„åˆ’åœ¨æ•´ä¸ªä»»åŠ¡è¿‡ç¨‹ä¸­çš„æœ‰æ•ˆæ€§ã€æ•ˆç‡å’Œæ½œåœ¨ç¼ºé™·ã€‚
      * **é‡å†™**ï¼š
          * å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œç”Ÿæˆä¸€ä¸ªä¿®æ­£åçš„ã€é€»è¾‘æ›´ä¸¥è°¨ã€æ›´å¯èƒ½æˆåŠŸçš„è§„åˆ’ (`plan_refined`)ã€‚
          * å¦‚æœä»»åŠ¡æˆåŠŸï¼Œæ€è€ƒæ˜¯å¦å­˜åœ¨æ›´ä¼˜ã€æ›´é«˜æ•ˆçš„è·¯å¾„æˆ–ç­–ç•¥ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªä¼˜åŒ–åçš„è§„åˆ’ (`plan_refined`)ã€‚
      * **ç”Ÿæˆåæ€ç¬”è®°**: LLM å¯¹è§„åˆ’çš„å®Œæ•´åˆ†æå’Œæ€è€ƒè¿‡ç¨‹è¢«æç‚¼ä¸º `reflection_note`ã€‚
  * **å†™å…¥è®°å¿†**: è°ƒç”¨ `memory_module.add`ï¼Œå°†åŸå§‹çš„ `task_instruction`ã€`master_plan`ã€æ–°ç”Ÿæˆçš„ `plan_refined` (JSON å­—ç¬¦ä¸²)ã€`reflection_note` ä»¥åŠä»»åŠ¡çŠ¶æ€ `status` ä¸€åŒå†™å…¥ `mainplan_experience_memory` é›†åˆä¸­ã€‚

**6. å…¶ä»–**

  * å¤§æ¨¡å‹è¾“å‡ºçš„ `reason` æ˜¯å…¶ `thought` éƒ¨åˆ†(CoT)çš„æ€»ç»“ï¼Œè¯·ä½ åœ¨promptä¸­æ˜ç¡®ã€‚


#### Data Organization

`results/ReflectionNavV3_[episode_id]/`
â”œâ”€â”€ `trajectory.json`          \# Mission execution log
â”œâ”€â”€ `episode_summary.json`       \# Mission outcome (success/failure)
â”œâ”€â”€ `rgb_images/`
â”‚   â””â”€â”€ `rgb_timestep_XXXX.png`   \# RGB visual snapshots
â””â”€â”€ `semantic_images/`
â”œâ”€â”€ `landmark_[id]_step_XXXX.png`  \# Semantic maps for navigation
â””â”€â”€ `semantic_[id]_step_XXXX.png`  \# Semantic maps for search



### **Configuration**

#### Key Settings (config.yaml)

  * **Memory**: `experience_db_path`, `max_retrieval_results`, `similarity_threshold`
  * **Navigation**: `max_search_radius`, `search_threshold`, `action_scale`
  * **Strategy**: `Maps_timeout`, `search_timeout`, `landmark_proximity`
  * **RAG**: `retrieval_interval`, `context_window_size`
  * **Reflection**: `enable_reflection`, `max_key_experiences`
"
```

### **Key Dependencies**

  * LangGraph: Workflow orchestration
  * ChromaDB: Vector database for experience storage
  * PIL/Pillow: Image processing and context loading
  * LangChain: Prompt management and LLM integration
  * OpenAI: LLM services and embeddings

